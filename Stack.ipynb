{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHsgbBSxxU03xQJSi/t5Vo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/surya211099/DetectingPhishingEmail/blob/main/Stack.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXHPgvuNXvIM",
        "outputId": "9bdc9e0b-fa08-49e9-e56f-27cd7eb989bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, log_loss, precision_score,\n",
        "    recall_score, f1_score, classification_report,\n",
        "    confusion_matrix\n",
        ")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Dessertation/phishing_numeric_dataset.csv\")\n",
        "\n",
        "features = ['sender', 'receiver', 'subject', 'body', 'urls', 'timestamp']\n",
        "X = df[features].values\n",
        "y = df['label'].values  # 0=legit, 1=phishing\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "lr = LogisticRegression(max_iter=1000)\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "lr_train_prob = lr.predict_proba(X_train)[:,1]\n",
        "lr_test_prob = lr.predict_proba(X_test)[:,1]\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=12,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "rf_train_prob = rf.predict_proba(X_train)[:,1]\n",
        "rf_test_prob = rf.predict_proba(X_test)[:,1]\n",
        "xgb = XGBClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.05,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    eval_metric='logloss',\n",
        "    random_state=42\n",
        ")\n",
        "xgb.fit(X_train, y_train)\n",
        "\n",
        "xgb_train_prob = xgb.predict_proba(X_train)[:,1]\n",
        "xgb_test_prob = xgb.predict_proba(X_test)[:,1]\n",
        "mlp_base = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dropout(0.2),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "mlp_base.compile(\n",
        "    optimizer=Adam(0.001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "mlp_base.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=40,\n",
        "    batch_size=64,\n",
        "    validation_split=0.1,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "mlp_train_prob = mlp_base.predict(X_train).flatten()\n",
        "mlp_test_prob = mlp_base.predict(X_test).flatten()\n",
        "X_train_stack = np.column_stack([\n",
        "    lr_train_prob,\n",
        "    rf_train_prob,\n",
        "    xgb_train_prob,\n",
        "    mlp_train_prob\n",
        "])\n",
        "\n",
        "X_test_stack = np.column_stack([\n",
        "    lr_test_prob,\n",
        "    rf_test_prob,\n",
        "    xgb_test_prob,\n",
        "    mlp_test_prob\n",
        "])\n",
        "meta_model = LogisticRegression()\n",
        "meta_model.fit(X_train_stack, y_train)\n",
        "y_pred_prob = meta_model.predict_proba(X_test_stack)[:,1]\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "ll = log_loss(y_test, y_pred_prob)\n",
        "prec = precision_score(y_test, y_pred)\n",
        "rec = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", acc)\n",
        "print(\"Log Loss:\", ll)\n",
        "print(\"Precision:\", prec)\n",
        "print(\"Recall:\", rec)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUAn9brEa4vl",
        "outputId": "2366b9ca-a9a4-4139-8325-b7c4c575f070"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6220 - loss: 0.6552 - val_accuracy: 0.6833 - val_loss: 0.6075\n",
            "Epoch 2/40\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6908 - loss: 0.6017 - val_accuracy: 0.7139 - val_loss: 0.5822\n",
            "Epoch 3/40\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7199 - loss: 0.5742 - val_accuracy: 0.7223 - val_loss: 0.5603\n",
            "Epoch 4/40\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7229 - loss: 0.5607 - val_accuracy: 0.7297 - val_loss: 0.5410\n",
            "Epoch 5/40\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7360 - loss: 0.5406 - val_accuracy: 0.7406 - val_loss: 0.5109\n",
            "Epoch 6/40\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7614 - loss: 0.5064 - val_accuracy: 0.7954 - val_loss: 0.4731\n",
            "Epoch 7/40\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7847 - loss: 0.4781 - val_accuracy: 0.8178 - val_loss: 0.4320\n",
            "Epoch 8/40\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7989 - loss: 0.4520 - val_accuracy: 0.8232 - val_loss: 0.4075\n",
            "Epoch 9/40\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8056 - loss: 0.4359 - val_accuracy: 0.8322 - val_loss: 0.3988\n",
            "Epoch 10/40\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8193 - loss: 0.4179 - val_accuracy: 0.8339 - val_loss: 0.3885\n",
            "Epoch 11/40\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8177 - loss: 0.4125 - val_accuracy: 0.8410 - val_loss: 0.3822\n",
            "Epoch 12/40\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8230 - loss: 0.4131 - val_accuracy: 0.8396 - val_loss: 0.3790\n",
            "Epoch 13/40\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8288 - loss: 0.3994 - val_accuracy: 0.8453 - val_loss: 0.3708\n",
            "Epoch 14/40\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8278 - loss: 0.4061 - val_accuracy: 0.8497 - val_loss: 0.3665\n",
            "Epoch 15/40\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8321 - loss: 0.3960 - val_accuracy: 0.8524 - val_loss: 0.3616\n",
            "Epoch 16/40\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.3854 - val_accuracy: 0.8486 - val_loss: 0.3595\n",
            "Epoch 17/40\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8350 - loss: 0.3917 - val_accuracy: 0.8557 - val_loss: 0.3541\n",
            "Epoch 18/40\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8422 - loss: 0.3806 - val_accuracy: 0.8552 - val_loss: 0.3535\n",
            "Epoch 19/40\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8434 - loss: 0.3773 - val_accuracy: 0.8573 - val_loss: 0.3481\n",
            "Epoch 20/40\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8424 - loss: 0.3774 - val_accuracy: 0.8587 - val_loss: 0.3474\n",
            "Epoch 21/40\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8457 - loss: 0.3737 - val_accuracy: 0.8576 - val_loss: 0.3444\n",
            "Epoch 22/40\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8463 - loss: 0.3717 - val_accuracy: 0.8628 - val_loss: 0.3391\n",
            "Epoch 23/40\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8519 - loss: 0.3652 - val_accuracy: 0.8612 - val_loss: 0.3354\n",
            "Epoch 24/40\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8525 - loss: 0.3599 - val_accuracy: 0.8595 - val_loss: 0.3375\n",
            "Epoch 25/40\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8533 - loss: 0.3546 - val_accuracy: 0.8590 - val_loss: 0.3380\n",
            "Epoch 26/40\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8482 - loss: 0.3689 - val_accuracy: 0.8639 - val_loss: 0.3275\n",
            "Epoch 27/40\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8560 - loss: 0.3534 - val_accuracy: 0.8633 - val_loss: 0.3302\n",
            "Epoch 28/40\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8565 - loss: 0.3512 - val_accuracy: 0.8625 - val_loss: 0.3288\n",
            "Epoch 29/40\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8557 - loss: 0.3512 - val_accuracy: 0.8652 - val_loss: 0.3238\n",
            "Epoch 30/40\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8535 - loss: 0.3539 - val_accuracy: 0.8650 - val_loss: 0.3242\n",
            "Epoch 31/40\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8525 - loss: 0.3522 - val_accuracy: 0.8663 - val_loss: 0.3237\n",
            "Epoch 32/40\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8558 - loss: 0.3486 - val_accuracy: 0.8672 - val_loss: 0.3206\n",
            "Epoch 33/40\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8617 - loss: 0.3434 - val_accuracy: 0.8680 - val_loss: 0.3227\n",
            "Epoch 34/40\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8563 - loss: 0.3457 - val_accuracy: 0.8680 - val_loss: 0.3198\n",
            "Epoch 35/40\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8617 - loss: 0.3397 - val_accuracy: 0.8647 - val_loss: 0.3189\n",
            "Epoch 36/40\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8618 - loss: 0.3422 - val_accuracy: 0.8685 - val_loss: 0.3187\n",
            "Epoch 37/40\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8628 - loss: 0.3404 - val_accuracy: 0.8704 - val_loss: 0.3137\n",
            "Epoch 38/40\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8657 - loss: 0.3332 - val_accuracy: 0.8699 - val_loss: 0.3138\n",
            "Epoch 39/40\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8642 - loss: 0.3355 - val_accuracy: 0.8696 - val_loss: 0.3131\n",
            "Epoch 40/40\n",
            "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8622 - loss: 0.3390 - val_accuracy: 0.8712 - val_loss: 0.3141\n",
            "\u001b[1m1146/1146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 980us/step\n",
            "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step\n",
            "Accuracy: 0.9381342062193126\n",
            "Log Loss: 0.16135657138832718\n",
            "Precision: 0.9568256578947368\n",
            "Recall: 0.9287567351825983\n",
            "F1 Score: 0.9425822784810126\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.95      0.93      4154\n",
            "           1       0.96      0.93      0.94      5011\n",
            "\n",
            "    accuracy                           0.94      9165\n",
            "   macro avg       0.94      0.94      0.94      9165\n",
            "weighted avg       0.94      0.94      0.94      9165\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[3944  210]\n",
            " [ 357 4654]]\n"
          ]
        }
      ]
    }
  ]
}